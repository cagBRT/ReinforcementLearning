{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "frozenlake3 (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEQB6zri6S9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWITHc8Qqmis",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQnVRywv6S92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Load Environment and Q-table structure\n",
        "#is_slippery = False - this is the deterministic situation\n",
        "#if you remove it, you get the slippery \n",
        "env = gym.make(\"FrozenLake-v0\", is_slippery=False) #change to true\n",
        "#env = gym.make(\"FrozenLake8x8-v0\", is_slippery=False) #change size of the pond \n",
        "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
        "# env.obeservation.n, env.action_space.n gives number of states and action in env loaded\n",
        "# 2. Parameters of Q-leanring\n",
        "eta = .628\n",
        "gma = .9\n",
        "episode = 10000\n",
        "rev_list = [] # rewards per episode calculate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnKhX_dM6S95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07269e80-2d6d-4592-b993-05bf395fea9a"
      },
      "source": [
        "# 3. Q-learning Algorithm\n",
        "for i in range(episode):\n",
        "    # Reset environment\n",
        "    print(\"New episode\")\n",
        "    print(\"state action\")\n",
        "    \n",
        "    s = env.reset()\n",
        "    info = env.step(env.action_space.sample())\n",
        "    rAll = 0\n",
        "    d = False\n",
        "    j = 0\n",
        "    #The Q-Table learning algorithm\n",
        "    while j < 99:\n",
        "        #env.render()\n",
        "        j+=1\n",
        "        # Choose action from Q table\n",
        "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
        "        #Get new state & reward from environment\n",
        "        s1,r,d,_ = env.step(a)\n",
        "        #Update Q-Table with new knowledge\n",
        "        Q[s,a] = Q[s,a] + eta*(r + gma*np.max(Q[s1,:]) - Q[s,a])\n",
        "        rAll += r\n",
        "        s = s1\n",
        "        print(\"%i %i\" %(s,a))\n",
        "        print(\"reward = %f\" %r)\n",
        "        print(info)\n",
        "        #print(s1)\n",
        "        if d == True:\n",
        "            break\n",
        "    print(\"number of steps = %i\" %j)\n",
        "    rev_list.append(rAll)\n",
        "    #env.render()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "1 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(0, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 16\n",
            "New episode\n",
            "state action\n",
            "9 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "10 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "11 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "12 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(8, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n",
            "New episode\n",
            "state action\n",
            "2 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "3 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "4 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "12 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "13 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "5 3\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "6 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "7 2\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "15 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "23 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "31 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "39 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "47 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "55 1\n",
            "reward = 0.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "63 1\n",
            "reward = 1.000000\n",
            "(1, 0.0, False, {'prob': 1.0})\n",
            "number of steps = 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmn7qHcz6S98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5dd87c7-990b-4ce3-ecdb-70178a59ef63"
      },
      "source": [
        "print (\"Reward Sum on all episodes %f\"  %(sum(rev_list)/episode))\n",
        "print (\"Final Values Q-Table\")\n",
        "print (Q)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward Sum on all episodes 0.833000\n",
            "Final Values Q-Table\n",
            "[[1.11319912e-04 5.28141578e-05 2.25607741e-01 1.84587795e-04]\n",
            " [0.00000000e+00 0.00000000e+00 2.28767925e-01 3.05007253e-04]\n",
            " [0.00000000e+00 0.00000000e+00 2.54186583e-01 0.00000000e+00]\n",
            " [2.13201270e-04 0.00000000e+00 2.82429536e-01 0.00000000e+00]\n",
            " [0.00000000e+00 3.13810596e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 4.30467210e-01 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 4.78296900e-01 0.00000000e+00]\n",
            " [0.00000000e+00 5.31441000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [3.84942841e-05 0.00000000e+00 3.06762232e-03 0.00000000e+00]\n",
            " [3.84942841e-05 0.00000000e+00 2.54186583e-01 1.20501358e-04]\n",
            " [0.00000000e+00 0.00000000e+00 2.82429536e-01 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 3.13810596e-01 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 3.48678440e-01 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.87420489e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 5.90490000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 6.56100000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 7.29000000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 8.10000000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 9.00000000e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dIRtKOz6S9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "428765f6-552d-4773-a03c-1c01ca04b9ef"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "for episode in range(5):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    print(\"****************************************************\")\n",
        "    print(\"EPISODE \", episode)\n",
        "\n",
        "    for step in range(99):\n",
        "        env.render()\n",
        "        # Take the action (index) that have the maximum expected future reward given that state\n",
        "        action = np.argmax(Q[state,:])\n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            break\n",
        "        state = new_state\n",
        "env.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************************************\n",
            "EPISODE  0\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFF\u001b[41mF\u001b[0mFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFFF\n",
            "FFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Up)\n",
            "SFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFF\u001b[41mF\u001b[0mF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFH\u001b[41mF\u001b[0m\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFH\u001b[41mF\u001b[0m\n",
            "FFFHFFFG\n",
            "****************************************************\n",
            "EPISODE  1\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFF\u001b[41mF\u001b[0mFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFFF\n",
            "FFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Up)\n",
            "SFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFF\u001b[41mF\u001b[0mF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFH\u001b[41mF\u001b[0m\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFH\u001b[41mF\u001b[0m\n",
            "FFFHFFFG\n",
            "****************************************************\n",
            "EPISODE  2\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFF\u001b[41mF\u001b[0mFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFFF\n",
            "FFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Up)\n",
            "SFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFF\u001b[41mF\u001b[0mF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFH\u001b[41mF\u001b[0m\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFH\u001b[41mF\u001b[0m\n",
            "FFFHFFFG\n",
            "****************************************************\n",
            "EPISODE  3\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFF\u001b[41mF\u001b[0mFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFFF\n",
            "FFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Up)\n",
            "SFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFF\u001b[41mF\u001b[0mF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFH\u001b[41mF\u001b[0m\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFH\u001b[41mF\u001b[0m\n",
            "FFFHFFFG\n",
            "****************************************************\n",
            "EPISODE  4\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFF\u001b[41mF\u001b[0mFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFF\u001b[41mF\u001b[0mFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFFF\n",
            "FFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Up)\n",
            "SFFFF\u001b[41mF\u001b[0mFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFF\u001b[41mF\u001b[0mF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Right)\n",
            "SFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHF\u001b[41mF\u001b[0m\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFF\u001b[41mF\u001b[0m\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFH\u001b[41mF\u001b[0m\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "  (Down)\n",
            "SFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFH\u001b[41mF\u001b[0m\n",
            "FFFHFFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru3falnU6S-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}